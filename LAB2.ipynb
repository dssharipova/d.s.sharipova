{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType, ArrayType, DoubleType\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.linalg import Vectors as MLLibVectors\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, lit\n",
    "from pyspark.sql.types import ArrayType, StringType, DoubleType\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.linalg import Vectors\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from scipy.spatial.distance import cosine\n",
    "from pyspark.ml.linalg import DenseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_courses = [[23126, u'en', u'Compass - powerful SASS library that makes your life easier'],\n",
    "                 [21617, u'en', u'Preparing for the AP* Computer Science A Exam \\u2014 Part 2'],\n",
    "                 [16627, u'es', u'Aprende Excel: Nivel Intermedio by Alfonso Rinsche'],\n",
    "                 [11556, u'es', u'Aprendizaje Colaborativo by UNID Universidad Interamericana para el Desarrollo'],\n",
    "                 [16704, u'ru', u'\\u041f\\u0440\\u043e\\u0433\\u0440\\u0430\\u043c\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435 \\u043d\\u0430 Lazarus'],\n",
    "                 [13702, u'ru', u'\\u041c\\u0430\\u0442\\u0435\\u043c\\u0430\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u0430\\u044f \\u044d\\u043a\\u043e\\u043d\\u043e\\u043c\\u0438\\u043a\\u0430']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "data_path = \"/labs/slaba02/DO_record_per_line.json\"\n",
    "data = spark.read.json(data_path)\n",
    "\n",
    "# Функция для очистки текста\n",
    "def clean_text(text):\n",
    "    regex = re.compile(u'[\\w\\d]{2,}', re.U)\n",
    "    return regex.findall(text.lower())\n",
    "\n",
    "# Регистрация UDF\n",
    "clean_text_udf = udf(clean_text, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение очистки текста к описаниям курсов\n",
    "data = data.withColumn(\"clean_desc\", clean_text_udf(col(\"desc\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+\n",
      "|                 cat|                desc| id|lang|                name|      provider|          clean_desc|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+\n",
      "|3/business_manage...|This course intro...|  4|  en|Accounting Cycle:...|Canvas Network|[this, course, in...|\n",
      "|              11/law|This online cours...|  5|  en|American Counter ...|Canvas Network|[this, online, co...|\n",
      "|5/computer_scienc...|This course is ta...|  6|  fr|Arithmétique: en ...|Canvas Network|[this, course, is...|\n",
      "|  14/social_sciences|We live in a digi...|  7|  en|Becoming a Dynami...|Canvas Network|[we, live, in, di...|\n",
      "|2/biology_life_sc...|This self-paced c...|  8|  en|           Bioethics|Canvas Network|[this, self, pace...|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование слов в векторы с помощью HashingTF\n",
    "hashingTF = HashingTF(inputCol=\"clean_desc\", outputCol=\"raw_features\", numFeatures=10000)\n",
    "featurizedData = hashingTF.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+--------------------+\n",
      "|                 cat|                desc| id|lang|                name|      provider|          clean_desc|        raw_features|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+--------------------+\n",
      "|3/business_manage...|This course intro...|  4|  en|Accounting Cycle:...|Canvas Network|[this, course, in...|(10000,[36,63,138...|\n",
      "|              11/law|This online cours...|  5|  en|American Counter ...|Canvas Network|[this, online, co...|(10000,[32,222,36...|\n",
      "|5/computer_scienc...|This course is ta...|  6|  fr|Arithmétique: en ...|Canvas Network|[this, course, is...|(10000,[30,118,12...|\n",
      "|  14/social_sciences|We live in a digi...|  7|  en|Becoming a Dynami...|Canvas Network|[we, live, in, di...|(10000,[493,572,7...|\n",
      "|2/biology_life_sc...|This self-paced c...|  8|  en|           Bioethics|Canvas Network|[this, self, pace...|(10000,[32,115,13...|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurizedData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление IDF на основе частоты слов\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "|                 cat|                desc| id|lang|                name|      provider|          clean_desc|        raw_features|            features|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "|3/business_manage...|This course intro...|  4|  en|Accounting Cycle:...|Canvas Network|[this, course, in...|(10000,[36,63,138...|(10000,[36,63,138...|\n",
      "|              11/law|This online cours...|  5|  en|American Counter ...|Canvas Network|[this, online, co...|(10000,[32,222,36...|(10000,[32,222,36...|\n",
      "|5/computer_scienc...|This course is ta...|  6|  fr|Arithmétique: en ...|Canvas Network|[this, course, is...|(10000,[30,118,12...|(10000,[30,118,12...|\n",
      "|  14/social_sciences|We live in a digi...|  7|  en|Becoming a Dynami...|Canvas Network|[we, live, in, di...|(10000,[493,572,7...|(10000,[493,572,7...|\n",
      "|2/biology_life_sc...|This self-paced c...|  8|  en|           Bioethics|Canvas Network|[this, self, pace...|(10000,[32,115,13...|(10000,[32,115,13...|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления косинусного сходства\n",
    "def cosine_similarity(v1, v2):\n",
    "    v1_np = np.array(v1)\n",
    "    v2_np = np.array(v2)\n",
    "    return float(np.dot(v1_np, v2_np) / (np.linalg.norm(v1_np) * np.linalg.norm(v2_np)))\n",
    "\n",
    "# Регистрация UDF для косинусного сходства\n",
    "cosine_similarity_udf = udf(cosine_similarity, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание словаря с рекомендациями\n",
    "recommendations = {}\n",
    "\n",
    "# Обработка каждого курса\n",
    "for course_id, lang, _ in given_courses:\n",
    "    # Выбор курсов того же языка\n",
    "    same_lang_courses = rescaledData.filter(col(\"lang\") == lang)\n",
    "    \n",
    "    # Получение вектора для данного курса\n",
    "    target_course_vector = same_lang_courses.filter(col(\"id\") == course_id).select(\"features\").collect()[0][0]\n",
    "    \n",
    "    # Создание Broadcast переменной для вектора данного курса\n",
    "    target_course_vector_broadcast = spark.sparkContext.broadcast(target_course_vector.toArray())\n",
    "    \n",
    "    # Вычисление косинусного сходства\n",
    "    def calculate_similarity(features):\n",
    "        return cosine_similarity(target_course_vector_broadcast.value, features.toArray())\n",
    "    \n",
    "    calculate_similarity_udf = udf(calculate_similarity, DoubleType())\n",
    "    \n",
    "    similarities = same_lang_courses.withColumn(\"similarity\", calculate_similarity_udf(col(\"features\")))\n",
    "    \n",
    "    # Отбор топ-10 курсов\n",
    "    top_courses = similarities.filter(col(\"id\") != course_id).orderBy(col(\"similarity\").desc(), col(\"name\")).limit(10)\n",
    "    recommended_ids = [row.id for row in top_courses.select(\"id\").collect()]\n",
    "    \n",
    "    # Сохранение рекомендаций\n",
    "    recommendations[str(course_id)] = recommended_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"lab02.json\", \"w\") as f:\n",
    "    json.dump(recommendations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
